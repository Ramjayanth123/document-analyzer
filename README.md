# ğŸš€ MCP Document Analyzer Server

## ğŸ“‹ Project Overview

This project implements a **Model Context Protocol (MCP) server** that provides text document analysis capabilities. The server can analyze documents for sentiment, extract keywords, calculate readability scores, and provide basic text statistics. ğŸ“Šâœ¨

## ğŸ¤– What is MCP (Model Context Protocol)?

MCP is a protocol that allows AI assistants to interact with external tools and data sources in a standardized way. Think of it as a bridge ğŸŒ‰ between AI systems and external services - the AI can call specific "tools" (functions) on the server and get structured responses.

**ğŸ”‘ Key MCP Concepts:**
- **ğŸ› ï¸ Tools**: Functions that the server exposes (like `analyze_document`, `get_sentiment`)
- **ğŸ“ Arguments**: Parameters passed to tools (like `document_id`, `text`)
- **ğŸ“¤ Responses**: Structured JSON responses from tool calls
- **ğŸŒ Protocol**: HTTP-based communication using JSON

## ğŸ—ï¸ Project Architecture

### ğŸ¤” Why This Approach?

I chose this architecture for several reasons:

1. **ğŸ¯ Simplicity**: Using basic HTTP server and JSON files keeps the implementation straightforward for a class assignment
2. **ğŸ“š Educational Value**: Building from scratch helps understand MCP concepts better than using existing frameworks
3. **ğŸ§© Modularity**: Separating analysis logic from server logic makes the code maintainable
4. **ğŸ”§ Extensibility**: Easy to add new analysis features or change storage methods

### ğŸ“ File Structure

```
document-analyzer/
â”œâ”€â”€ ğŸ–¥ï¸ server.py              # Main MCP server (HTTP request handling)
â”œâ”€â”€ ğŸ”¬ document_analyzer.py   # Core analysis logic (sentiment, keywords, etc.)
â”œâ”€â”€ ğŸ§ª test_client.py         # Test client to demonstrate functionality
â”œâ”€â”€ ğŸ“¦ requirements.txt       # Python dependencies
â”œâ”€â”€ ğŸ“– README.md             # This documentation
â””â”€â”€ ğŸ“‚ documents/            # Created automatically when server runs
    â”œâ”€â”€ ğŸ“„ documents.json    # Document metadata storage
    â””â”€â”€ ğŸ“ content/          # Individual document text files
        â”œâ”€â”€ ğŸ“ doc_001.txt
        â”œâ”€â”€ ğŸ“ doc_002.txt
        â””â”€â”€ ...
```

## ğŸ”§ Implementation Details

### 1. ğŸ’¾ Document Storage (`documents/`)

**ğŸ¤” Why JSON Files?**
- âœ… Simple to implement and understand
- ğŸ› Human-readable for debugging
- ğŸš« No database setup required
- ğŸ“Š Sufficient for assignment scope (15+ documents)

**ğŸ—ï¸ Structure:**
- `documents.json`: Stores metadata (title, author, category, filename)
- `content/`: Individual `.txt` files with document content
- This separation keeps metadata queries fast while allowing full-text search

### 2. ğŸ”¬ Core Analysis Module (`document_analyzer.py`)

This module contains all the text analysis logic:

#### ğŸ˜Š Sentiment Analysis
- **ğŸ“š Library**: TextBlob (simple and effective)
- **ğŸ“Š Method**: Polarity scoring (-1 to +1)
- **ğŸ·ï¸ Categories**: Positive (>0.1), Negative (<-0.1), Neutral (between)
- **âœ¨ Why TextBlob**: Easy to use, no complex setup, good for educational purposes

#### ğŸ” Keyword Extraction
- **âš™ï¸ Method**: Word frequency counting with stop word filtering
- **ğŸ¯ Approach**: Simple but effective for most texts
- **ğŸš« Stop Words**: Common words (the, and, is, etc.) filtered out
- **ğŸ’¡ Why This Approach**: Transparent, explainable, no complex NLP models needed

#### ğŸ“– Readability Scoring
- **ğŸ“ Formula**: Simplified Flesch Reading Ease
- **ğŸ§® Calculation**: Based on average sentence length and syllable count
- **ğŸ“Š Levels**: Very easy to very difficult (7 categories)
- **ğŸ† Why Flesch**: Well-established, widely understood metric

#### ğŸ“ˆ Basic Statistics
- ğŸ”¤ Character count (with/without spaces)
- ğŸ“ Word count, sentence count, paragraph count
- ğŸ“ Average words per sentence
- **ğŸ¯ Why These Metrics**: Fundamental text properties useful for analysis

### 3. ğŸ–¥ï¸ MCP Server (`server.py`)

The HTTP server that implements the MCP protocol:

#### ğŸ—ï¸ Server Design
- **ğŸ”§ Base**: Python's built-in `http.server` (no external dependencies)
- **ğŸŒ Protocol**: HTTP with JSON payloads
- **ğŸ”— Endpoints**: 
  - `GET /health` - Health check â¤ï¸
  - `GET /tools` - List available tools ğŸ› ï¸
  - `POST /` - Tool execution âš¡

#### ğŸ› ï¸ MCP Tool Implementation
Each tool follows this pattern:
1. âœ… Validate required arguments
2. ğŸ”„ Call appropriate analyzer method
3. ğŸ“¤ Return structured JSON response
4. ğŸš¨ Handle errors gracefully

**ğŸ¯ Available Tools:**
- `analyze_document(document_id)` - Complete document analysis ğŸ“Š
- `get_sentiment(text)` - Sentiment analysis for any text ğŸ˜Š
- `extract_keywords(text, limit)` - Keyword extraction ğŸ”
- `add_document(document_data)` - Add new document â•
- `search_documents(query)` - Search by content/metadata ğŸ”

### 4. ğŸ§ª Test Client (`test_client.py`)

Demonstrates how to interact with the MCP server:
- ğŸ“¡ Makes HTTP requests to test all tools
- ğŸ“‹ Shows expected request/response formats
- âœ… Validates server functionality
- ğŸ“– Serves as usage example

## ğŸ¤” Technical Decisions Explained

### ğŸ Why Python?
- ğŸ› ï¸ Rich ecosystem for text processing (TextBlob, NLTK, regex)
- ğŸ–¥ï¸ Simple HTTP server capabilities
- ğŸ“š Easy to understand and modify
- âš¡ Good for rapid prototyping

### ğŸŒ Why HTTP Instead of WebSockets?
- ğŸ¯ Simpler to implement and test
- ğŸ”§ Standard HTTP tools work (curl, Postman, browsers)
- ğŸ› Stateless design is easier to debug
- âœ… Sufficient for the assignment requirements

### ğŸ§® Why Simple Algorithms?
- **ğŸ” Transparency**: Easy to understand how results are calculated
- **âš¡ Speed**: Fast processing without complex model loading
- **ğŸ”’ Reliability**: Fewer dependencies, less likely to break
- **ğŸ“š Educational**: Shows fundamental concepts without black-box complexity

### ğŸ“„ Why JSON Storage?
- **ğŸ‘ï¸ Human-readable**: Easy to inspect and debug
- **ğŸ¯ Simple**: No database setup or SQL knowledge required
- **ğŸ“¦ Portable**: Works across different systems
- **âœ… Sufficient**: Handles 15+ documents easily

## ğŸ“š Sample Documents

The server automatically creates 15+ sample documents covering various topics:
- ğŸ’» Technology (AI, quantum computing, space exploration)
- ğŸŒ Environment (climate change, renewable energy)
- ğŸ¥ Health (sleep science, psychology)
- ğŸ¨ Culture (music, storytelling, urban gardening)
- ğŸ’° Economics (future of work, cryptocurrency)
- ğŸ§˜ Philosophy (mindfulness, ethics)

**ğŸ¯ Why This Variety?**
- ğŸ“ Tests analysis across different writing styles
- ğŸ˜Š Demonstrates sentiment analysis on various topics
- ğŸ” Provides diverse keyword extraction examples
- ğŸ“– Shows readability differences between technical and casual writing

## ğŸš€ Installation and Usage

### 1. âš™ï¸ Setup Environment
```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 2. ğŸ–¥ï¸ Start the Server
```bash
python server.py
```

The server will:
- ğŸ“š Create sample documents automatically
- ğŸŒ Start listening on `http://localhost:8000`
- ğŸ“‹ Display available tools and usage information

### 3. ğŸ§ª Test the Server
```bash
# In another terminal
python test_client.py
```

This will run comprehensive tests of all MCP tools.

### 4. ğŸ”§ Manual Testing
You can also test manually using curl:

```bash
# Health check
curl http://localhost:8000/health

# Get available tools
curl http://localhost:8000/tools

# Analyze sentiment
curl -X POST http://localhost:8000 \
  -H "Content-Type: application/json" \
  -d '{"tool": "get_sentiment", "arguments": {"text": "I love this project!"}}'

# Search documents
curl -X POST http://localhost:8000 \
  -H "Content-Type: application/json" \
  -d '{"tool": "search_documents", "arguments": {"query": "artificial intelligence"}}'
```

## ğŸ”— MCP Protocol Details

### ğŸ“¤ Request Format
```json
{
  "tool": "tool_name",
  "arguments": {
    "parameter1": "value1",
    "parameter2": "value2"
  }
}
```

### ğŸ“¥ Response Format
```json
{
  "tool": "tool_name",
  "result": {
    // Tool-specific results
  },
  "timestamp": "2024-01-01T12:00:00"
}
```

### âŒ Error Format
```json
{
  "error": "Error description"
}
```

## ğŸ”® Extension Possibilities

This implementation can be extended in several ways:

### ğŸ§  Analysis Enhancements
- More sophisticated sentiment analysis (VADER, transformers)
- Named Entity Recognition (NER)
- Topic modeling
- Language detection
- Plagiarism detection

### ğŸ’¾ Storage Improvements
- SQLite database for better querying
- Full-text search with indexing
- Document versioning
- Bulk import/export

### ğŸ–¥ï¸ Server Features
- Authentication and authorization
- Rate limiting
- Caching for frequently accessed documents
- WebSocket support for real-time updates
- API documentation generation

### ğŸ”Œ Integration Options
- Connect to external APIs (OpenAI, Google Cloud NLP)
- Support for different document formats (PDF, Word, HTML)
- Integration with document management systems
- Real-time collaboration features

## ğŸ“ Learning Outcomes

By implementing this project, you learn:

1. **ğŸ¤– MCP Protocol**: How AI assistants communicate with external tools
2. **ğŸŒ HTTP Servers**: Building web services from scratch
3. **ğŸ“Š Text Analysis**: Fundamental NLP techniques and their applications
4. **ğŸ”— API Design**: Creating clean, consistent interfaces
5. **ğŸš¨ Error Handling**: Robust error management in distributed systems
6. **ğŸ§ª Testing**: Comprehensive testing strategies for web services
7. **ğŸ“– Documentation**: Writing clear technical documentation

## ğŸ”§ Troubleshooting

### âš ï¸ Common Issues

**Server won't start:**
- Check if port 8000 is already in use
- Ensure all dependencies are installed
- Verify Python version (3.7+ recommended)

**Analysis errors:**
- TextBlob might need NLTK data: `python -c "import nltk; nltk.download('punkt')"`
- Check document encoding (should be UTF-8)

**Test client failures:**
- Ensure server is running before starting tests
- Check firewall settings for localhost connections
- Verify requests library is installed

### âš¡ Performance Considerations

For production use, consider:
- Using a proper web framework (FastAPI, Flask)
- Implementing connection pooling
- Adding caching for frequently analyzed documents
- Using a real database for better query performance
- Implementing proper logging and monitoring

## ğŸ¯ Conclusion

This MCP Document Analyzer Server demonstrates how to build a functional text analysis service that follows the Model Context Protocol. The implementation prioritizes simplicity and educational value while providing a solid foundation for more advanced features. âœ¨

The project showcases key concepts in web services, text processing, and API design, making it an excellent learning tool for understanding how AI assistants interact with external services. ğŸš€

---

**ğŸ‰ Happy Coding! ğŸ‰** 